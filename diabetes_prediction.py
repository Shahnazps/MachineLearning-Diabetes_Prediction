# -*- coding: utf-8 -*-
"""diabetes_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p5_Z1fLP1q8lunjwaKWg0OeN8QkmY_Dg
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from sklearn.linear_model import LogisticRegression

from google.colab import drive
drive.mount('/content/drive')

from zipfile import ZipFile

filename = "/content/drive/MyDrive/Datasets/diabetes_prediction/archive.zip"
with ZipFile (filename,'r') as zip:
  zip.printdir()
  zip.extractall("/content/drive/MyDrive/Datasets/diabetes_prediction/data")

rootDir = "/content/drive/MyDrive/Datasets/diabetes_prediction/data/diabetes.csv"

data = pd.read_csv(rootDir)
data.shape

data.head()

#heatmap
import seaborn as sns
corr = data.corr()
print(corr)
sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns)

#checking for null values
data.isnull().values.any()

#checking whether the data is balanced
diabetes_true_count = len(data.loc[data['Outcome'] == 1])
diabetes_false_count = len(data.loc[data['Outcome'] == 0])
(diabetes_true_count,diabetes_false_count)

#train,test,split

from sklearn.model_selection import train_test_split
data.columns
feature_columns = []
for col in data.columns:
  feature_columns.append(col)
#print(feature_columns)
column_len = len(feature_columns)
predicted_class = [feature_columns[column_len-1]]
print(predicted_class)
feature_columns.remove(feature_columns[column_len-1])
print(feature_columns)

x = data[feature_columns].values
y = data[predicted_class].values

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=10)

#checking for missing values or zeroes
print("total number of rows ",len(data))
for i in range(1,len(feature_columns)):
  col = feature_columns[i]
  print("no.of rows missing [{}] : {}".format(col,len(data.loc[data[col] == 0])))

#replace missing values with mean

from sklearn.impute import SimpleImputer

fill_values = SimpleImputer(missing_values=0,strategy='mean')
x_train = fill_values.fit_transform(x_train)
x_test = fill_values.fit_transform(x_test)

diabetesCheck = LogisticRegression()
diabetesCheck.fit(x_train,y_train)

accuracy = diabetesCheck.score(x_test,y_test)
print("Accuracy = ",accuracy*100,"%")

#data normalization
means = np.mean(x_train,axis =0 )
stds = np.std(x_train,axis=0)

x_train = (x_train - means)/stds
x_test = (x_test - means)/stds

diabetesCheck = LogisticRegression()
diabetesCheck.fit(x_train,y_train)

accuracy = diabetesCheck.score(x_test,y_test)
print("Accuracy = ",accuracy*100,"%")

#random forest
from sklearn.ensemble import RandomForestClassifier
random_forest_model = RandomForestClassifier(random_state=10)
random_forest_model.fit(x_train,y_train.ravel())

predict_train_data = random_forest_model.predict(x_test)

from sklearn import metrics

print("Accuracy = {0:.3f}".format(metrics.accuracy_score(y_test,predict_train_data)))

x_test

